{
  "scan_timestamp": "2025-01-15T14:30:00Z",
  "aws_account_id": "123456789012",
  "aws_region": "us-east-1",
  "findings": [
    {
      "finding_id": "AWS-BEDROCK-001",
      "resource_arn": "arn:aws:bedrock:us-east-1:123456789012:provisioned-model/prod-chatbot-model",
      "severity": "High",
      "technical_finding": "Bedrock model 'prod-chatbot-model' does not have guardrails configured. Model is exposed to prompt injection, jailbreaking, and content policy violations.",
      "mitigation_applied": "Recommended: Create and attach Bedrock Guardrail with content filters, PII detection, and word/phrase blocking. Use guardrailIdentifier in model invocations.",
      "mappings": {
        "nist_ai_rmf": [
          "MEASURE 2.4 (Privacy Controls)",
          "MANAGE 1.1 (Safety Controls)",
          "GOVERN 1.3 (Risk Management Processes)"
        ],
        "iso_42001": [
          "Annex A.8.2 (Data for AI System Development)",
          "Clause 8.2 (Risk Assessment and Treatment)",
          "Clause 6.1.3 (Risk Management)"
        ],
        "mitre_atlas": [
          "AML.T0051 (LLM Prompt Injection)",
          "AML.T0054 (LLM Jailbreaking)",
          "AML.T0040 (ML Model Inference API Access)"
        ]
      },
      "executive_summary": "The absence of guardrails on this production chatbot model creates direct regulatory exposure under the EU AI Act's transparency and safety requirements. Attackers can exploit this vulnerability through prompt injection (MITRE AML.T0051) to bypass content policies and extract sensitive training data. Implementing guardrails satisfies NIST AI RMF MEASURE 2.4 privacy controls and ISO 42001 Clause 8.2 risk treatment requirements, demonstrating due diligence in AI system safety."
    },
    {
      "finding_id": "AWS-SAGEMAKER-001",
      "resource_arn": "arn:aws:sagemaker:us-east-1:123456789012:model/fraud-detection-v2",
      "severity": "High",
      "technical_finding": "SageMaker model 'fraud-detection-v2' has no Model Card. Lack of documentation creates compliance gaps for AI governance frameworks and prevents verification of intended use, training data provenance, and risk assessment.",
      "mitigation_applied": "Required: Create Model Card using sagemaker:CreateModelCard API. Document intended use, training data characteristics, performance metrics, limitations, and risk assessment. Assign risk rating.",
      "mappings": {
        "nist_ai_rmf": [
          "MAP 1.2 (Intended Purpose and Context)",
          "MEASURE 2.1 (Performance Metrics)",
          "GOVERN 1.7 (Documentation and Transparency)",
          "GOVERN 4.1 (Accountability)"
        ],
        "iso_42001": [
          "Clause 7.2 (AI System Inventory)",
          "Clause 8.3 (Risk Assessment)",
          "Annex A.8.2 (Data for AI System)",
          "Annex A.6.2 (Documentation Requirements)"
        ],
        "mitre_atlas": [
          "AML.T0020 (Poison Training Data)",
          "AML.T0043 (Craft Adversarial Data)"
        ]
      },
      "executive_summary": "Deploying this fraud detection model without documentation exposes the organization to audit failures and regulatory penalties under financial services AI governance requirements. The lack of model cards prevents detection of data poisoning attacks (MITRE AML.T0020) and makes it impossible to verify that the model is being used within its validated scope. Creating comprehensive Model Card documentation fulfills NIST AI RMF MAP 1.2 intended purpose requirements and ISO 42001 Annex A.6.2 documentation obligations, essential for SOX and GLBA compliance in financial services."
    },
    {
      "finding_id": "AWS-BEDROCK-002",
      "resource_arn": "arn:aws:bedrock:us-east-1:123456789012:custom-model/customer-service-fine-tuned",
      "severity": "Medium",
      "technical_finding": "Custom Bedrock model 'customer-service-fine-tuned' detected. Fine-tuned models require explicit guardrail configuration to maintain safety controls.",
      "mitigation_applied": "Recommended: Document intended use case, implement guardrails appropriate for fine-tuning data domain, and enforce guardrails in all production invocations.",
      "mappings": {
        "nist_ai_rmf": [
          "MEASURE 2.4 (Privacy Controls)",
          "MAP 1.2 (Intended Use Documentation)"
        ],
        "iso_42001": [
          "Annex A.8.2 (Data for AI)",
          "Clause 7.2 (AI System Inventory)"
        ],
        "mitre_atlas": [
          "AML.T0051 (LLM Prompt Injection)",
          "AML.T0043 (Craft Adversarial Data)"
        ]
      },
      "executive_summary": "Fine-tuned language models inherit risks from both the base model and custom training data, requiring enhanced controls. Without documented guardrails, this model can be exploited via prompt injection (MITRE AML.T0051) to generate responses outside its intended customer service domain. Implementing domain-specific guardrails addresses NIST AI RMF MEASURE 2.4 and ISO 42001 Annex A.8.2 data governance requirements."
    }
  ],
  "summary": {
    "total_findings": 3,
    "severity_breakdown": {
      "Critical": 0,
      "High": 2,
      "Medium": 1,
      "Low": 0,
      "Informational": 0
    }
  }
}
