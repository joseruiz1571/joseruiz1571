"""
AI Governance Scanner - Core Schema Definitions

Defines the standard JSON schema for security findings that map
technical vulnerabilities to compliance frameworks and attack vectors.
"""

from dataclasses import dataclass, field, asdict
from typing import List, Dict, Optional
from enum import Enum
import json


class Severity(Enum):
    """Finding severity levels"""
    CRITICAL = "Critical"
    HIGH = "High"
    MEDIUM = "Medium"
    LOW = "Low"
    INFO = "Informational"


@dataclass
class ComplianceMappings:
    """Maps technical findings to compliance frameworks and threat vectors"""
    nist_ai_rmf: List[str] = field(default_factory=list)
    iso_42001: List[str] = field(default_factory=list)
    mitre_atlas: List[str] = field(default_factory=list)

    def to_dict(self) -> Dict:
        """Convert to dictionary for JSON serialization"""
        return {
            "nist_ai_rmf": self.nist_ai_rmf,
            "iso_42001": self.iso_42001,
            "mitre_atlas": self.mitre_atlas
        }


@dataclass
class Finding:
    """
    Core finding schema - the "Rosetta Stone" that translates
    technical reality into governance language.

    Example:
        finding = Finding(
            finding_id="AWS-BEDROCK-001",
            resource_arn="arn:aws:bedrock:us-east-1:123456789:model/...",
            severity=Severity.HIGH,
            technical_finding="No Bedrock Guardrail attached to production model",
            mitigation_applied="Manual - Attach Guardrail with PII filter",
            mappings=ComplianceMappings(
                nist_ai_rmf=["MEASURE 2.4 (Privacy)", "MANAGE 1.1 (Safety)"],
                iso_42001=["Annex A.8.2 (Data for AI)", "Clause 8.2 (Risk Management)"],
                mitre_atlas=["AML.T0054 (LLM Jailbreaking)", "AML.T0051 (Prompt Injection)"]
            )
        )
    """
    finding_id: str
    resource_arn: str
    severity: Severity
    technical_finding: str
    mitigation_applied: str
    mappings: ComplianceMappings
    executive_summary: Optional[str] = None  # Generated by AI narrator

    def to_dict(self) -> Dict:
        """Convert to dictionary for JSON serialization"""
        return {
            "finding_id": self.finding_id,
            "resource_arn": self.resource_arn,
            "severity": self.severity.value,
            "technical_finding": self.technical_finding,
            "mitigation_applied": self.mitigation_applied,
            "mappings": self.mappings.to_dict(),
            "executive_summary": self.executive_summary
        }

    def to_json(self, indent: int = 2) -> str:
        """Convert to formatted JSON string"""
        return json.dumps(self.to_dict(), indent=indent)


@dataclass
class ScanReport:
    """Container for multiple findings from a scan run"""
    scan_timestamp: str
    aws_account_id: str
    aws_region: str
    findings: List[Finding] = field(default_factory=list)

    def add_finding(self, finding: Finding):
        """Add a finding to the report"""
        self.findings.append(finding)

    def get_severity_counts(self) -> Dict[str, int]:
        """Get count of findings by severity"""
        counts = {s.value: 0 for s in Severity}
        for finding in self.findings:
            counts[finding.severity.value] += 1
        return counts

    def to_dict(self) -> Dict:
        """Convert to dictionary for JSON serialization"""
        return {
            "scan_timestamp": self.scan_timestamp,
            "aws_account_id": self.aws_account_id,
            "aws_region": self.aws_region,
            "findings": [f.to_dict() for f in self.findings],
            "summary": {
                "total_findings": len(self.findings),
                "severity_breakdown": self.get_severity_counts()
            }
        }

    def to_json(self, indent: int = 2) -> str:
        """Convert to formatted JSON string"""
        return json.dumps(self.to_dict(), indent=indent)
